### 读取FITS文件并画图☺
 * .info查看标头信息。
 * hdulist[0].data访问图像数据。
 * matplotlib用以可视化数据。
***✍e.g.读取一系列FITS文件数据，将他们堆栈并求平均，画图展示：***
<blockquote style="border-left: 5px solid #FFA006;">

```python
 def mean_fits(a):
  n=len(a)
  hdulist = fits.open(a[0])
  data = hdulist[0].data
  hdulist.close()  #读取完这个文件记得关闭该文件！
  #前面打开了索引为0的文件，这里就从1开始。
  for i in range(1,n):
    hdulist = fits.open(a[i])
    data+=hdulist[0].data
    hdulist.close()
  m=data/n
  return m

if __name__ == '__main__':
  data  = mean_fits(['image0.fits', 'image1.fits', 'image2.fits'])
  print(data[100, 100])
  import matplotlib.pyplot as plt
  plt.imshow(data.T, cmap=plt.cm.viridis)
  plt.colorbar()
  plt.show()
``` 
运行结果：
0.0173565863321
<div align=left><Image src="图\FITS图1.png" width="300" height="300"></div>

</blockquote>

***✍e.g.编写一个函数，该函数获取一系列FITS文件，将它们加载到 NumPy 数组中，并计算图像的中位数，
输出时按照“中位数、运行时间、内存大小”进行输出：***

<blockquote style="border-left: 5px solid #9266FF;">

```python
import time, numpy as np
from astropy.io import fits
def median_fits(filenames):
#启动计时器
  start = time.time()   
#把所有要读取的FITS文件名放到这个数组里面
  FITS_list = []
  for filename in filenames: 
    hdulist = fits.open(filename)
    FITS_list.append(hdulist[0].data)
    hdulist.close()
#通过dstack函数堆栈图像数据
  FITS_stack = np.dstack(FITS_list)
#通过median函数求堆栈后的中位数
  median = np.median(FITS_stack, axis=2)
#计算所耗内存
  memory = FITS_stack.nbytes
  # or, equivalently:
  #memory = 200 * 200 * len(filenames) * FITS_stack.itemsize
#将内存转化为kB单位  
  memory /= 1024
  #结束计时器
  stop = time.time() - start   
  return median, stop, memory

#例如我们想求11个FITS文件的中位数，只用输出坐标[100,100]对应的数据即可
result = median_fits(['image{}.fits'.format(str(i)) for i in range(11)])
print(result[0][100, 100], result[1], result[2]) 
```

</blockquote>

#### p.s.读取.data文件,指定选取的列数，数组保存了文件的每行数据
```python
import numpy as np
#文件名，分隔符，跳过的行号，显示的列号。
cat = np.loadtxt('super.csv', delimiter=',', skiprows=1, usecols=[0, 1])
print(cat[0])
```
#### p.s. enumerate()函数的用法

```python
data = ['apple', 'banana', 'cherry']  
for i, row in enumerate(data, 1):  
    print(f"Index: {i}, Value: {row}")
```
* `enumerate(data, 1)`：这个函数将 `data` 中的每个元素与一个计数器结合，计数器是从 1 开始的（而不是默认的 0）。`enumerate` 函数会返回一个**包含元素的索引和值的元组**，形如 `(index, value)`。

* `for i, row in ...`：这里我们通过解包元组，将索引存储在变量 i 中，将元素存储在 `row` 中。这样可以在每次迭代中同时访问当前元素及其索引。
* 结果：
```
Index: 1, Value: apple  
Index: 2, Value: banana  
Index: 3, Value: cherry
```

### SQL数据库的访问
<blockquote style="border-left: 5px solid #72CD76;">

1. 假设我在数据库中有一个名为Stars 的数据表，要查询其所有数据(不区分大小写):

```sql
SELECT * FROM Stars;
```
选择特定的列，查找满足条件的信息：

```sql
SELECT koi_name, radius FROM Stars 
WHERE radius < 2;
```
语句末尾要加 ***''  ;  ''***
查找的逻辑语句：
```sql
SELECT 2 > 3;
SELECT NOT 2 > 3;
SELECT 2 = 3;
```
分别返回false,true,false.
下面的代码寻找radius在1~2之间的数据:
```sql
SELECT radius FROM  Star
WHERE radius BETWEEN 1 AND 2;
```

2. 如果拿到一个陌生的表，可以通过`\d Planet`操作查看基本信息.
例如，返回如下信息：
```sql
              Table "public.planet"
+-------------+-----------------------+-----------+
|   Column    |         Type          | Modifiers |
+-------------+-----------------------+-----------+
| kepler_id   | integer               | not null  |
| koi_name    | character varying(20) | not null  |
| kepler_name | character varying(20) |           |
| status      | character varying(20) |           |
| period      | double precision      |           |
| radius      | real                  |           |
| t_eq        | integer               |           |
+-------------+-----------------------+-----------+
Indexes:
    "planet_pkey" PRIMARY KEY, btree (koi_name)
```
其中`character varying(20)`表示该类型可以容纳20个数据，
`not null`意味着在向此表添加数据时，必须指定这些属性，不能为空，而其他属性可以留空
例如，在表中寻找不是`NULL`的目标：
```sql
SELECT kepler_name, radius 
FROM Planet
WHERE
  radius BETWEEN 1 AND 3 AND
  kepler_name IS NOT NULL;
```
查询表中总共多少行，多少非`NULL`行:
```sql
SELECT COUNT(*) FROM Planet
WHERE kepler_name IS NOT NULL;
```
计算各种值：
```sql
SELECT SUM(t_eff)/COUNT(*), AVG(t_eff)
FROM Star;
```
排序(第二行降序，第三行升序，limit限制输出的行数)：
```sql
SELECT koi_name, radius FROM Planet 
ORDER BY radius DESC;
ORDER BY radius ;
LIMIT 5;
```
**注意顺序：**
对表中数据进行计数，必须先`Select From`再`GROUP BY`,计数用`Having Count`,最后排序`Order by ...`
```sql
SELECT radius, COUNT(koi_name) 
FROM Planet 
WHERE t_eq BETWEEN 500 AND 1000
GROUP BY radius
HAVING COUNT(koi_name) > 1;
```
***代码逻辑：***
##### `Select...From`, 从...表中找出某一列数据
##### `Where...`, 找出...那几行数据
##### `Group by...`, 将...数据分组以便使用count等函数
##### `Having Count()`, 计数()的内容出现了多少次 ,要在select后面加上Count()
##### `Order by...`, 按照某一顺序排序...

3. 表中数据的连接
通过点 **“ . ”** 访问某个表的某个数据：
```sql
SELECT Star.kepler_id, Planet.koi_name
FROM Star As s, Planet As p
WHERE s.kepler_id = p.kepler_id;
```
##### ✍e.g.编写一个查询，返回其半径之比大于太阳与地球半径之比的每颗***恒星和行星对***的半径。根据恒星半径按降序对结果进行排序。使用 and 作为恒星和行星半径的属性别名。
```sql
#注意要寻找恒星行星对，即两者的kepler_id要相同。
#将恒星和行星的radius按照点“ . ”索引出来，命名为sun_radius和planet_radius
select Star.radius , Planet.radius
from Star  , Planet 
where Star.radius>Planet.radius and Star.kepler_id = Planet.kepler_id
#或写成
#SELECT Star.radius, COUNT(Planet.koi_name)
#FROM Star
#JOIN Planet USING (kepler_id)
order by Star.radius  desc;
```
连接表中数据的另一种方法,采用`Join 表名称 Using 列名`,
或者`Join on 选择条件`
`Join...Using...`相当于上面的`where 表名称1 = 表名称2`
```sql
SELECT Star.kepler_id, Planet.koi_name
FROM Star
JOIN Planet USING (kepler_id);
JOIN Planet ON Star.kepler_id = Planet.kepler_id;
```
创建外部链接，例如我们想找恒星对应的行星，即使没有对应行星的恒星或者没有对应恒星的行星也将他显示出来。
`LEFT OUTER JOIN`:保留**Select左边表**的所有行，无对应值用NULL代替。
`RIGHT OUTER JOIN`:保留**Select右边表**的所有行，无对应值用NULL代替。
`FULL OUTER JOIN`:保留**Select的表**的所有行，无对应值用NULL代替。
```sql
#Left表明保留左边即S.kepler_id的所有行。
SELECT S.kepler_id, P.koi_name
FROM Star as S
LEFT OUTER JOIN Planet as P USING(kepler_id);
```
</blockquote>

### 构建回归分类器
<blockquote style="border-left: 5px solid #FF2333;">
1.基本步骤▲：

```python
from sklearn.tree import DecisionTreeRegressor
#初始化
dtr = DecisionTreeRegressor()
#训练模型，参数为训练集
dtr.fit(features, targets)
#预测，参数为测试集
predictions = dtr.predict(test_features)
```

##### ✍e.g.加载数据并采用决策树预测
我们将features数据一分为二，一半当做训练集，一半当做测试集。
```python
import numpy as np
from sklearn.tree import DecisionTreeRegressor
#假设我们事先采用这样的函数
def get_features_targets(data):
  features = np.zeros(shape=(len(data), 4));features[:, 0] = data['u'] - data['g']
  features[:, 1] = data['g'] - data['r'];features[:, 2] = data['r'] - data['i']
  features[:, 3] = data['i'] - data['z'];targets = data['redshift']
  return features, targets

#我们以split为界限，划分数据
split = features.shape[0]//2
train_features, test_features = features[:split], feature[split:]
train_targets, test_targets = targets[:split], target[split:]

#加载数据并获取features和targets
data = np.load('sdss_galaxy_colors.npy')
features, targets = get_features_targets(data)
#初始化
# 设置最大树深度防止过拟合！
dtr = DecisionTreeRegressor(max_depth = 19)
#训练模型
dtr.fit(train_features, train_targets)
#预测,采用test_features当做测试集
predictions = dtr.predict(test_features)
#显示前几个元素
print(predictions[:5])

```
2. 上面的步骤叫做Hold out 验证，但准确性无法保证，现在我们看k-fold交叉验证(k-fold Cross Validation),**将数据分为k个子集，每个子集分别进行训练和预测**

<span style="color:#6633DD">

**k-fold交叉验证函数逻辑：**
* 把数据分为训练集和测试集
* 训练模型
* 预测模型
* 计算中位数差值

</span>

**✍e.g.将上面的代码用k-fold交叉验证进行修改**
```python
import numpy as np
from matplotlib import pyplot as plt
from sklearn.model_selection import KFold
from sklearn.tree import DecisionTreeRegressor
#同上
def get_features_targets(data):
  features = np.zeros((data.shape[0], 4));features[:, 0] = data['u'] - data['g']
  features[:, 1] = data['g'] - data['r'];features[:, 2] = data['r'] - data['i']
  features[:, 3] = data['i'] - data['z'];targets = data['redshift']
  return features, targets
#计算中位数差值判断模型优劣
def median_diff(predicted, actual):
  return np.median(np.abs(predicted - actual))

def cross_validate_predictions(model, features, targets, k):
#最关键的部分，构建交叉检验函数▲▲▲
  kf = KFold(n_splits=k, shuffle=True)
#将要预测的值初始化
  all_predictions = np.zeros_like(targets)
  for train_indices, test_indices in kf.split(features):
    #把数据分为训练集和测试集
    train_features, test_features = features[train_indices], features[test_indices]
    train_targets, test_targets = targets[train_indices], targets[test_indices]
    #训练模型
    model.fit(train_features, train_targets)
    #预测
    predictions = model.predict(test_features)    
    #把得到的值赋给前面的初始化数组
    all_predictions[test_indices] = predictions
  #该交叉验证函数返回预测值数组
  return all_predictions    
if __name__ == "__main__":
  data = np.load('./sdss_galaxy_colors.npy')
  features, targets = get_features_targets(data)
  #初始化
  dtr = DecisionTreeRegressor(max_depth=19)
  #交叉验证
  predictions = cross_validate_predictions(dtr, features, targets, 10)
  #计算中位数差
  diffs = median_diff(predictions, targets)
  print('Median difference: {:.3f}'.format(diffs))
  #画散点图查看效果
  plt.scatter(targets, predictions, s=0.4);plt.xlim((0, targets.max()))
  plt.ylim((0, predictions.max()));plt.xlabel('Measured Redshift')
  plt.ylabel('Predicted Redshift');plt.show()

```
* 另外，sklearn库有一个直接进行k-fold交叉验证的函数：
`from sklearn.model_selection import cross_val_predict
`
</blockquote>